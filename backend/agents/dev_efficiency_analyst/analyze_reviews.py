#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
from datetime import datetime
import statistics

def parse_datetime(dt_str):
    """è§£æISOæ ¼å¼æ—¶é—´"""
    return datetime.fromisoformat(dt_str.replace('Z', '+00:00'))

def calculate_review_time(created, updated):
    """è®¡ç®—å®¡æŸ¥è€—æ—¶ï¼ˆå°æ—¶ï¼‰"""
    created_dt = parse_datetime(created)
    updated_dt = parse_datetime(updated)
    return (updated_dt - created_dt).total_seconds() / 3600

def analyze_gerrit_data(file_path):
    """åˆ†æGerritä»£ç å®¡æŸ¥æ•°æ®"""
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    changes = data['changes']
    
    print("=" * 60)
    print("ğŸ“Š ä»£ç å®¡æŸ¥æ•ˆç‡åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    print()
    
    # 1. è®¡ç®—Reviewè€—æ—¶
    review_times = []
    rework_counts = []
    
    print("## è¯¦ç»†å˜æ›´ä¿¡æ¯\n")
    for change in changes:
        created = change['created']
        updated = change['updated']
        review_time = calculate_review_time(created, updated)
        review_times.append(review_time)
        
        # è®¡ç®—è¿”å·¥æ¬¡æ•°ï¼ˆrevisionæ•°é‡ - 1ï¼‰
        revision_count = len(change['revisions'])
        rework_count = revision_count - 1
        rework_counts.append(rework_count)
        
        print(f"### {change['id']} - {change['subject']}")
        print(f"  - é¡¹ç›®: {change['project']}")
        print(f"  - åˆ†æ”¯: {change['branch']}")
        print(f"  - åˆ›å»ºæ—¶é—´: {created}")
        print(f"  - åˆå¹¶æ—¶é—´: {updated}")
        print(f"  - Reviewè€—æ—¶: {review_time:.1f} å°æ—¶")
        print(f"  - Revisionæ•°é‡: {revision_count}")
        print(f"  - è¿”å·¥æ¬¡æ•°: {rework_count}")
        print()
    
    # 2. ç»Ÿè®¡åˆ†æ
    print("=" * 60)
    print("## ğŸ“ˆ å…³é”®æŒ‡æ ‡")
    print("=" * 60)
    print()
    
    # Reviewè€—æ—¶ç»Ÿè®¡
    avg_review_time = statistics.mean(review_times)
    median_review_time = statistics.median(review_times)
    max_review_time = max(review_times)
    min_review_time = min(review_times)
    
    print(f"### Reviewè€—æ—¶ç»Ÿè®¡")
    print(f"  - å¹³å‡è€—æ—¶: {avg_review_time:.1f} å°æ—¶")
    print(f"  - ä¸­ä½æ•°è€—æ—¶: {median_review_time:.1f} å°æ—¶")
    print(f"  - æœ€é•¿è€—æ—¶: {max_review_time:.1f} å°æ—¶")
    print(f"  - æœ€çŸ­è€—æ—¶: {min_review_time:.1f} å°æ—¶")
    print()
    
    # è¿”å·¥ç‡ç»Ÿè®¡
    total_changes = len(changes)
    changes_with_rework = sum(1 for r in rework_counts if r > 0)
    rework_rate = (changes_with_rework / total_changes) * 100
    avg_rework_count = statistics.mean(rework_counts)
    
    print(f"### è¿”å·¥æƒ…å†µç»Ÿè®¡")
    print(f"  - éœ€è¦è¿”å·¥çš„å˜æ›´: {changes_with_rework}/{total_changes}")
    print(f"  - è¿”å·¥ç‡: {rework_rate:.1f}%")
    print(f"  - å¹³å‡è¿”å·¥æ¬¡æ•°: {avg_rework_count:.2f}")
    print()
    
    # é¡¹ç›®åˆ†å¸ƒ
    project_stats = {}
    for change in changes:
        project = change['project']
        if project not in project_stats:
            project_stats[project] = {'count': 0, 'review_times': []}
        project_stats[project]['count'] += 1
        review_time = calculate_review_time(change['created'], change['updated'])
        project_stats[project]['review_times'].append(review_time)
    
    print(f"### é¡¹ç›®åˆ†å¸ƒ")
    for project, stats in project_stats.items():
        avg_time = statistics.mean(stats['review_times'])
        print(f"  - {project}: {stats['count']} ä¸ªå˜æ›´ï¼Œå¹³å‡è€—æ—¶ {avg_time:.1f} å°æ—¶")
    print()
    
    # 3. é—®é¢˜æ£€æµ‹
    print("=" * 60)
    print("## ğŸš¨ é—®é¢˜æ£€æµ‹")
    print("=" * 60)
    print()
    
    issues_found = []
    
    # æ£€æŸ¥Reviewè€—æ—¶
    MEDIAN_THRESHOLD = 24  # 24å°æ—¶
    if median_review_time > MEDIAN_THRESHOLD:
        issues_found.append({
            'level': 'ä¸¥é‡',
            'type': 'Reviewè€—æ—¶è¿‡é•¿',
            'current': f'{median_review_time:.1f}å°æ—¶',
            'threshold': f'{MEDIAN_THRESHOLD}å°æ—¶',
            'impact': 'å¯èƒ½å»¶è¯¯è¿­ä»£äº¤ä»˜ï¼Œå½±å“å›¢é˜Ÿååé‡'
        })
    
    # æ£€æŸ¥è¿”å·¥ç‡
    REWORK_RATE_THRESHOLD = 15  # 15%
    if rework_rate > REWORK_RATE_THRESHOLD:
        issues_found.append({
            'level': 'è­¦å‘Š',
            'type': 'è¿”å·¥ç‡åé«˜',
            'current': f'{rework_rate:.1f}%',
            'threshold': f'{REWORK_RATE_THRESHOLD}%',
            'impact': 'ä»£ç è´¨é‡éœ€è¦æ”¹è¿›ï¼Œæˆ–Reviewæ ‡å‡†ä¸ä¸€è‡´'
        })
    
    # æ£€æŸ¥è¶…é•¿è€—æ—¶
    LONG_REVIEW_THRESHOLD = 72  # 72å°æ—¶ (3å¤©)
    long_reviews = [t for t in review_times if t > LONG_REVIEW_THRESHOLD]
    if long_reviews:
        issues_found.append({
            'level': 'è­¦å‘Š',
            'type': 'å­˜åœ¨è¶…é•¿Review',
            'current': f'{len(long_reviews)}ä¸ªå˜æ›´è¶…è¿‡{LONG_REVIEW_THRESHOLD}å°æ—¶',
            'threshold': f'{LONG_REVIEW_THRESHOLD}å°æ—¶',
            'impact': 'å¯èƒ½å­˜åœ¨Reviewé˜»å¡æˆ–è¢«é—å¿˜çš„æƒ…å†µ'
        })
    
    if issues_found:
        for idx, issue in enumerate(issues_found, 1):
            print(f"### é—®é¢˜ {idx}: {issue['type']}")
            print(f"  - ä¸¥é‡ç¨‹åº¦: {issue['level']}")
            print(f"  - å½“å‰å€¼: {issue['current']}")
            print(f"  - é˜ˆå€¼: {issue['threshold']}")
            print(f"  - å½±å“: {issue['impact']}")
            print()
    else:
        print("âœ… æœªå‘ç°æ˜æ˜¾é—®é¢˜ï¼Œæ‰€æœ‰æŒ‡æ ‡åœ¨æ­£å¸¸èŒƒå›´å†…ã€‚")
        print()
    
    # 4. æ”¹è¿›å»ºè®®
    print("=" * 60)
    print("## ğŸ’¡ æ”¹è¿›å»ºè®®")
    print("=" * 60)
    print()
    
    if median_review_time > MEDIAN_THRESHOLD:
        print("1. **åŠ å¿«Reviewå“åº”é€Ÿåº¦**")
        print("   - è®¾ç½®Review SLAç›®æ ‡ï¼ˆå»ºè®®24å°æ—¶å†…é¦–æ¬¡å“åº”ï¼‰")
        print("   - ä½¿ç”¨è½®å€¼åˆ¶åº¦ç¡®ä¿åŠæ—¶Review")
        print("   - å¯¹è¶…æ—¶Reviewè‡ªåŠ¨æé†’")
        print()
    
    if rework_rate > REWORK_RATE_THRESHOLD:
        print("2. **é™ä½è¿”å·¥ç‡**")
        print("   - æäº¤å‰å¼ºåŒ–è‡ªæµ‹å’Œä»£ç æ£€æŸ¥")
        print("   - ç»Ÿä¸€ä»£ç è§„èŒƒå’ŒReviewæ ‡å‡†")
        print("   - å¯¹é«˜é¢‘è¿”å·¥é—®é¢˜åšå›¢é˜Ÿåˆ†äº«")
        print()
    
    if long_reviews:
        print("3. **é¿å…Reviewé˜»å¡**")
        print("   - æ‹†åˆ†å¤§å‹å˜æ›´ä¸ºå°æ‰¹æ¬¡æäº¤")
        print("   - ä¸»åŠ¨è·Ÿè¿›é•¿æ—¶é—´æœªå“åº”çš„Review")
        print("   - è€ƒè™‘å¢åŠ Reviewerèµ„æº")
        print()
    
    print("4. **æŒç»­ç›‘æ§**")
    print("   - å»ºç«‹æ¯æ—¥æ•ˆç‡çœ‹æ¿")
    print("   - å®šæœŸï¼ˆå‘¨/æœˆï¼‰å›é¡¾è¶‹åŠ¿")
    print("   - ä¸å›¢é˜Ÿå…±äº«å…³é”®æŒ‡æ ‡")
    print()
    
    return {
        'review_times': review_times,
        'median_review_time': median_review_time,
        'avg_review_time': avg_review_time,
        'rework_rate': rework_rate,
        'issues_found': issues_found
    }

if __name__ == '__main__':
    analyze_gerrit_data('data/mock_gerrit_data.json')
