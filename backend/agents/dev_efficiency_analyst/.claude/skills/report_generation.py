#!/usr/bin/env python3
"""
Report Generation Skill
ç”Ÿæˆæ ‡å‡†åŒ–æŠ¥å‘Šçš„èƒ½åŠ›

æ”¯æŒæŠ¥å‘Šç±»å‹ï¼š
1. ä»£ç å®¡æŸ¥æ•ˆç‡æŠ¥å‘Šï¼ˆGerritæ•°æ®ï¼‰
2. é—¨ç¦æ„å»ºæ•ˆç‡æŠ¥å‘Šï¼ˆBuildæ•°æ®ï¼‰
3. ç»¼åˆç ”å‘æ•ˆèƒ½æŠ¥å‘Š
"""

import json
import sys
from datetime import datetime
from typing import Dict, Any, List, Optional


def generate_efficiency_report(metrics: Dict[str, Any], anomalies: list) -> str:
    """
    ç”Ÿæˆç ”å‘æ•ˆèƒ½æŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰

    Args:
        metrics: æŒ‡æ ‡æ•°æ®
        anomalies: å¼‚å¸¸åˆ—è¡¨

    Returns:
        Markdownæ ¼å¼çš„æŠ¥å‘Šå†…å®¹
    """
    today = datetime.now().strftime("%Y-%m-%d")

    report = f"""# ç ”å‘æ•ˆèƒ½æ—¥æŠ¥ - {today}

## ğŸ“Š å…³é”®æŒ‡æ ‡

| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|-----|------|------|
| æ€»æäº¤æ•° | {metrics.get('total_changes', 0)} | æ˜¨æ—¥åˆå¹¶çš„ä»£ç å˜æ›´æ•°é‡ |
| Reviewä¸­ä½è€—æ—¶ | {metrics.get('median_review_time_hours', 0):.1f} å°æ—¶ | 50%çš„Reviewåœ¨æ­¤æ—¶é—´å†…å®Œæˆ |
| Review P95è€—æ—¶ | {metrics.get('p95_review_time_hours', 0):.1f} å°æ—¶ | 95%çš„Reviewåœ¨æ­¤æ—¶é—´å†…å®Œæˆ |
| å¹³å‡Reviewè€—æ—¶ | {metrics.get('avg_review_time_hours', 0):.1f} å°æ—¶ | æ‰€æœ‰Reviewçš„å¹³å‡è€—æ—¶ |
| è¿”å·¥ç‡ | {metrics.get('rework_rate_percent', 0):.1f}% | éœ€è¦å¤šæ¬¡ä¿®æ”¹çš„æäº¤å æ¯” |
| è¿”å·¥æ¬¡æ•° | {metrics.get('rework_count', 0)} | å®é™…å‘ç”Ÿè¿”å·¥çš„æäº¤æ•°é‡ |

"""

    # å¼‚å¸¸å‘ç°éƒ¨åˆ†
    if anomalies:
        report += "\n## ğŸ” å¼‚å¸¸å‘ç°\n\n"
        for idx, anomaly in enumerate(anomalies, 1):
            severity_emoji = "ğŸš¨" if anomaly['severity'] == 'critical' else "âš ï¸"
            report += f"{severity_emoji} **å¼‚å¸¸ {idx}**: {anomaly['message']}\n"
            report += f"   - å½“å‰å€¼: {anomaly['value']:.1f}\n"
            report += f"   - é˜ˆå€¼: {anomaly['threshold']}\n\n"

        # å½±å“åˆ†æ
        report += "\n### ğŸ“‰ å½±å“åˆ†æ\n\n"
        if any(a['type'] in ['high_review_time', 'high_p95_time'] for a in anomalies):
            report += "- Reviewè€—æ—¶è¿‡é•¿å¯èƒ½å¯¼è‡´æœ¬å‘¨è¿­ä»£å»¶æœŸ\n"
            report += "- å½±å“å¼€å‘è€…å·¥ä½œèŠ‚å¥å’Œå£«æ°”\n"

        if any(a['type'] == 'high_rework_rate' for a in anomalies):
            report += "- é«˜è¿”å·¥ç‡è¡¨æ˜ä»£ç è´¨é‡æˆ–éœ€æ±‚ç†è§£å­˜åœ¨é—®é¢˜\n"
            report += "- å¢åŠ äº†å›¢é˜Ÿçš„æ— æ•ˆåŠ³åŠ¨æ—¶é—´\n"

        # æ”¹è¿›å»ºè®®
        report += "\n## ğŸ’¡ æ”¹è¿›å»ºè®®\n\n"
        suggestions = []

        if any(a['type'] in ['high_review_time', 'high_p95_time'] for a in anomalies):
            suggestions.extend([
                "1. **åŠ å¿«Reviewå“åº”**: è®¾ç½®Reviewæé†’ï¼Œç¡®ä¿2å°æ—¶å†…é¦–æ¬¡å“åº”",
                "2. **å¹¶è¡ŒReview**: æ·»åŠ å¤šä¸ªReviewerï¼Œå‡å°‘ç­‰å¾…æ—¶é—´",
                "3. **æ‹†åˆ†å¤§PR**: å°†å¤§å‹å˜æ›´æ‹†åˆ†ä¸ºå°çš„å¯ç‹¬ç«‹Reviewçš„éƒ¨åˆ†"
            ])

        if any(a['type'] == 'high_rework_rate' for a in anomalies):
            suggestions.extend([
                "4. **æå‡ä»£ç è´¨é‡**: åŠ å¼ºæœ¬åœ°æµ‹è¯•å’Œè‡ªæ£€",
                "5. **éœ€æ±‚æ¾„æ¸…**: å¼€å‘å‰ä¸äº§å“ç¡®è®¤éœ€æ±‚ç»†èŠ‚",
                "6. **ä»£ç è§„èŒƒåŸ¹è®­**: ç»„ç»‡å›¢é˜Ÿä»£ç è§„èŒƒåŸ¹è®­"
            ])

        report += "\n".join(suggestions[:5])  # æœ€å¤š5æ¡å»ºè®®

    else:
        report += "\n## âœ… è¿è¡ŒçŠ¶æ€\n\n"
        report += "æ‰€æœ‰æŒ‡æ ‡æ­£å¸¸ï¼Œå›¢é˜Ÿç ”å‘æ•ˆç‡ä¿æŒè‰¯å¥½çŠ¶æ€ã€‚\n"

    # æ•°æ®æ¥æº
    report += f"\n\n---\n*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
    report += "*æ•°æ®æ¥æº: Gerrit API*\n"

    return report


def generate_build_report(data: Dict[str, Any]) -> str:
    """
    ç”Ÿæˆé—¨ç¦æ„å»ºæ•ˆç‡æŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰

    Args:
        data: æ„å»ºåˆ†ææ•°æ®ï¼ŒåŒ…å« metrics, platform_percentiles, trend, anomalies ç­‰

    Returns:
        Markdownæ ¼å¼çš„æŠ¥å‘Šå†…å®¹
    """
    today = datetime.now().strftime("%Y-%m-%d")
    days = data.get("analysis_period_days", 7)
    
    report = f"""# é—¨ç¦æ„å»ºæ•ˆç‡æŠ¥å‘Š - {today}

> åˆ†æå‘¨æœŸ: æœ€è¿‘ **{days}** å¤©

"""
    
    # åŸºç¡€æŒ‡æ ‡
    metrics = data.get("metrics", {})
    if metrics:
        total_builds = metrics.get("total_builds", 0)
        duration = metrics.get("total_duration_minutes", {})
        
        report += """## ğŸ“Š åŸºç¡€æŒ‡æ ‡

| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|-----|------|------|
"""
        report += f"| åˆ†ææ„å»ºæ•° | **{total_builds:,}** æ¬¡ | åˆ†æå‘¨æœŸå†…çš„æ„å»ºä»»åŠ¡æ•°é‡ |\n"
        report += f"| å¹³å‡è€—æ—¶ | **{duration.get('avg', 0):.1f}** åˆ†é’Ÿ | æ‰€æœ‰æ„å»ºçš„å¹³å‡ç«¯åˆ°ç«¯è€—æ—¶ |\n"
        report += f"| P50è€—æ—¶ | **{duration.get('p50', 0):.1f}** åˆ†é’Ÿ | 50%çš„æ„å»ºåœ¨æ­¤æ—¶é—´å†…å®Œæˆ |\n"
        report += f"| P95è€—æ—¶ | **{duration.get('p95', 0):.1f}** åˆ†é’Ÿ | 95%çš„æ„å»ºåœ¨æ­¤æ—¶é—´å†…å®Œæˆ |\n"
        report += f"| P99è€—æ—¶ | **{duration.get('p99', 0):.1f}** åˆ†é’Ÿ | 99%çš„æ„å»ºåœ¨æ­¤æ—¶é—´å†…å®Œæˆ |\n"
        report += f"| æœ€é•¿è€—æ—¶ | **{duration.get('max', 0):.1f}** åˆ†é’Ÿ | æœ€æ…¢æ„å»ºçš„è€—æ—¶ |\n"
        report += "\n"
        
        # å„é˜¶æ®µè€—æ—¶
        stage_ratio = metrics.get("stage_ratio_percent", {})
        if stage_ratio:
            report += """### â±ï¸ å„é˜¶æ®µè€—æ—¶å æ¯”

| é˜¶æ®µ | å æ¯” | è¯´æ˜ |
|-----|------|------|
"""
            report += f"| æ„å»º(build) | **{stage_ratio.get('build', 0):.1f}%** | å®é™…ç¼–è¯‘è€—æ—¶ |\n"
            report += f"| ä¸‹è½½(download) | **{stage_ratio.get('download', 0):.1f}%** | ä»£ç ä¸‹è½½è€—æ—¶ |\n"
            report += f"| æ‹·è´(copy) | **{stage_ratio.get('copy', 0):.1f}%** | æ–‡ä»¶æ‹·è´è€—æ—¶ |\n"
            report += f"| OFPå¤„ç† | **{stage_ratio.get('ofp', 0):.1f}%** | OFPå¤„ç†è€—æ—¶ |\n"
            report += "\n"
    
    # è¶‹åŠ¿åˆ†æ
    trend = data.get("trend", {})
    if trend:
        overall_trend = trend.get("overall_trend", "unknown")
        trend_map = {
            "worsening": "ğŸ“ˆ **æ¶åŒ–ä¸­** - æ„å»ºè€—æ—¶åœ¨å¢åŠ ",
            "improving": "ğŸ“‰ **æ”¹å–„ä¸­** - æ„å»ºè€—æ—¶åœ¨å‡å°‘",
            "stable": "â¡ï¸ **ä¿æŒç¨³å®š** - æ„å»ºè€—æ—¶å˜åŒ–ä¸å¤§",
            "insufficient_data": "âš ï¸ **æ•°æ®ä¸è¶³** - æ— æ³•åˆ¤æ–­è¶‹åŠ¿"
        }
        
        report += f"""## ğŸ“ˆ è¶‹åŠ¿åˆ†æ

**æ•´ä½“è¶‹åŠ¿**: {trend_map.get(overall_trend, 'æœªçŸ¥')}

"""
        
        # è¶‹åŠ¿æ•°æ®è¡¨
        trend_data = trend.get("data", [])
        if trend_data and len(trend_data) > 0:
            report += "| æ—¥æœŸ | æ„å»ºæ•° | å¹³å‡è€—æ—¶(åˆ†é’Ÿ) | ç¯æ¯”å˜åŒ– |\n"
            report += "|------|--------|---------------|----------|\n"
            for t in trend_data[-7:]:  # æœ€è¿‘7ä¸ªå‘¨æœŸ
                change = t.get("change_percent")
                change_str = f"{change:+.1f}%" if change is not None else "-"
                change_icon = ""
                if change is not None:
                    if change > 10:
                        change_icon = "ğŸ”´"
                    elif change < -10:
                        change_icon = "ğŸŸ¢"
                report += f"| {t.get('period', '')} | {t.get('build_count', 0):,} | {t.get('avg_pipeline_minutes', 0):.1f} | {change_icon} {change_str} |\n"
            report += "\n"
    
    # å¼‚å¸¸å‘Šè­¦
    anomalies_data = data.get("anomalies", {})
    anomalies_list = anomalies_data.get("anomalies", [])
    if anomalies_list:
        report += "## âš ï¸ å¼‚å¸¸å‘Šè­¦\n\n"
        for anomaly in anomalies_list:
            severity = anomaly.get("severity", "warning")
            severity_icon = "ğŸ”´" if severity == "critical" else "ğŸŸ¡"
            report += f"{severity_icon} **{anomaly.get('type', 'unknown')}**: {anomaly.get('message', '')}\n\n"
            
            details = anomaly.get("details", [])
            if details and isinstance(details, list):
                if anomaly.get("type") == "slow_builds":
                    report += "| ä»»åŠ¡å· | å¹³å° | è€—æ—¶(åˆ†é’Ÿ) |\n"
                    report += "|--------|------|------------|\n"
                    for d in details[:5]:
                        report += f"| {d.get('task_num', '')} | {d.get('platform', '')} | {d.get('duration_minutes', 0):.0f} |\n"
                elif anomaly.get("type") == "worsening_platforms":
                    report += "| å¹³å° | å½“å‰å¹³å‡(åˆ†é’Ÿ) | ä¹‹å‰å¹³å‡(åˆ†é’Ÿ) | å˜åŒ– |\n"
                    report += "|------|---------------|---------------|------|\n"
                    for d in details:
                        report += f"| {d.get('platform', '')} | {d.get('recent_avg_minutes', 0):.0f} | {d.get('prev_avg_minutes', 0):.0f} | +{d.get('change_percent', 0):.0f}% |\n"
                report += "\n"
    
    # å¹³å°åˆ†æ
    platform_data = data.get("platform_percentiles", {})
    platforms = platform_data.get("platforms", [])
    if platforms:
        report += """## ğŸ† å¹³å°æ„å»ºè€—æ—¶æ’è¡Œ

> æŒ‰P95è€—æ—¶æ’åºï¼Œè¶Šé«˜è¡¨ç¤ºè¶Šéœ€è¦å…³æ³¨

| æ’å | å¹³å° | P50(åˆ†é’Ÿ) | P95(åˆ†é’Ÿ) | P99(åˆ†é’Ÿ) | æ„å»ºæ•° |
|------|------|-----------|-----------|-----------|--------|
"""
        sorted_platforms = sorted(platforms, key=lambda x: float(x.get("p95", 0) or 0), reverse=True)
        for i, p in enumerate(sorted_platforms[:10], 1):
            p95_val = float(p.get("p95", 0) or 0)
            p50_val = float(p.get("p50", 0) or 0)
            p99_val = float(p.get("p99", 0) or 0)
            count_val = int(p.get("count", 0) or 0)
            attention = "âš ï¸" if p95_val > 120 else ""
            report += f"| {i} {attention} | {p.get('platform', '')} | {p50_val:.0f} | {p95_val:.0f} | {p99_val:.0f} | {count_val:,} |\n"
        report += "\n"
    
    # æ”¹è¿›å»ºè®®
    report += """## ğŸ’¡ æ”¹è¿›å»ºè®®

"""
    suggestions = []
    
    # æ ¹æ®å¼‚å¸¸ç”Ÿæˆå»ºè®®
    if anomalies_list:
        for anomaly in anomalies_list:
            if anomaly.get("type") == "slow_builds":
                suggestions.append("1. **å…³æ³¨æ…¢æ„å»º**: æ’æŸ¥è¶…è¿‡P95çš„æ„å»ºä»»åŠ¡ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨å¼‚å¸¸")
            elif anomaly.get("type") == "worsening_platforms":
                suggestions.append("2. **å¹³å°ä¼˜åŒ–**: é‡ç‚¹å…³æ³¨è€—æ—¶æ¶åŒ–çš„å¹³å°ï¼Œåˆ†ææ ¹å› ")
    
    # æ ¹æ®è¶‹åŠ¿ç”Ÿæˆå»ºè®®
    if trend.get("overall_trend") == "worsening":
        suggestions.append("3. **è¶‹åŠ¿è­¦ç¤º**: æ„å»ºè€—æ—¶æ•´ä½“åœ¨æ¶åŒ–ï¼Œå»ºè®®æ’æŸ¥åŸºç¡€è®¾æ–½æˆ–ä»£ç å˜åŒ–")
    
    # æ ¹æ®é˜¶æ®µå æ¯”ç”Ÿæˆå»ºè®®
    stage_ratio = metrics.get("stage_ratio_percent", {})
    if stage_ratio:
        if stage_ratio.get("download", 0) > 30:
            suggestions.append("4. **ä¼˜åŒ–ä¸‹è½½**: ä¸‹è½½é˜¶æ®µå æ¯”è¿‡é«˜ï¼Œè€ƒè™‘å¢åŠ ç¼“å­˜æˆ–ä¼˜åŒ–ç½‘ç»œ")
        if stage_ratio.get("build", 0) > 70:
            suggestions.append("5. **ç¼–è¯‘ä¼˜åŒ–**: ç¼–è¯‘é˜¶æ®µå æ¯”æœ€å¤§ï¼Œå¯è€ƒè™‘å¢é‡ç¼–è¯‘æˆ–å¹¶è¡Œç¼–è¯‘ä¼˜åŒ–")
    
    if not suggestions:
        suggestions.append("âœ… å½“å‰æ„å»ºæ•ˆç‡æ­£å¸¸ï¼Œç»§ç»­ä¿æŒ")
    
    report += "\n".join(suggestions)
    
    # æ•°æ®æ¥æº
    report += f"\n\n---\n*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
    report += "*æ•°æ®æ¥æº: é—¨ç¦æ„å»ºæ•°æ®åº“ (rn_test.personal_build)*\n"

    return report


def generate_combined_report(
    gerrit_data: Optional[Dict[str, Any]] = None,
    build_data: Optional[Dict[str, Any]] = None
) -> str:
    """
    ç”Ÿæˆç»¼åˆç ”å‘æ•ˆèƒ½æŠ¥å‘Š
    
    Args:
        gerrit_data: Gerritåˆ†ææ•°æ®
        build_data: æ„å»ºåˆ†ææ•°æ®
        
    Returns:
        Markdownæ ¼å¼çš„ç»¼åˆæŠ¥å‘Š
    """
    today = datetime.now().strftime("%Y-%m-%d")
    
    report = f"""# ç ”å‘æ•ˆèƒ½ç»¼åˆæŠ¥å‘Š - {today}

"""
    
    # ä»£ç å®¡æŸ¥éƒ¨åˆ†
    if gerrit_data:
        report += "## ğŸ” ä»£ç å®¡æŸ¥æ•ˆç‡\n\n"
        metrics = gerrit_data.get("metrics", {})
        report += f"- æ€»æäº¤æ•°: **{metrics.get('total_changes', 0)}**\n"
        report += f"- Reviewä¸­ä½è€—æ—¶: **{metrics.get('median_review_time_hours', 0):.1f}** å°æ—¶\n"
        report += f"- Review P95è€—æ—¶: **{metrics.get('p95_review_time_hours', 0):.1f}** å°æ—¶\n"
        report += f"- è¿”å·¥ç‡: **{metrics.get('rework_rate_percent', 0):.1f}%**\n\n"
    
    # æ„å»ºæ•ˆç‡éƒ¨åˆ†
    if build_data:
        report += "## ğŸ—ï¸ é—¨ç¦æ„å»ºæ•ˆç‡\n\n"
        metrics = build_data.get("metrics", {})
        duration = metrics.get("total_duration_minutes", {})
        report += f"- åˆ†ææ„å»ºæ•°: **{metrics.get('total_builds', 0):,}** æ¬¡\n"
        report += f"- æ„å»ºP50è€—æ—¶: **{duration.get('p50', 0):.1f}** åˆ†é’Ÿ\n"
        report += f"- æ„å»ºP95è€—æ—¶: **{duration.get('p95', 0):.1f}** åˆ†é’Ÿ\n"
        
        trend = build_data.get("trend", {})
        trend_map = {"worsening": "æ¶åŒ–ä¸­", "improving": "æ”¹å–„ä¸­", "stable": "ç¨³å®š"}
        if trend.get("overall_trend"):
            report += f"- è¶‹åŠ¿: **{trend_map.get(trend['overall_trend'], 'æœªçŸ¥')}**\n"
        report += "\n"
    
    # ç»¼åˆå¼‚å¸¸
    all_anomalies = []
    if gerrit_data and gerrit_data.get("anomalies"):
        all_anomalies.extend([("ä»£ç å®¡æŸ¥", a) for a in gerrit_data["anomalies"]])
    if build_data:
        build_anomalies = build_data.get("anomalies", {}).get("anomalies", [])
        all_anomalies.extend([("é—¨ç¦æ„å»º", a) for a in build_anomalies])
    
    if all_anomalies:
        report += "## âš ï¸ ç»¼åˆå‘Šè­¦\n\n"
        for source, anomaly in all_anomalies:
            severity_icon = "ğŸ”´" if anomaly.get("severity") == "critical" else "ğŸŸ¡"
            report += f"{severity_icon} **[{source}]** {anomaly.get('message', '')}\n"
        report += "\n"
    else:
        report += "## âœ… çŠ¶æ€æ­£å¸¸\n\næ‰€æœ‰æŒ‡æ ‡æ­£å¸¸ï¼Œå›¢é˜Ÿç ”å‘æ•ˆç‡ä¿æŒè‰¯å¥½çŠ¶æ€ã€‚\n\n"
    
    report += f"\n---\n*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
    
    return report


def generate_problem_report(data: Dict[str, Any]) -> str:
    """
    ç”Ÿæˆé—®é¢˜å¯¼å‘çš„æ„å»ºåˆ†ææŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰
    
    é‡ç‚¹å‘ˆç°é—®é¢˜å’Œè§£å†³æ€è·¯ï¼Œè€Œéç®€å•ç½—åˆ—æŒ‡æ ‡
    
    Args:
        data: é—®é¢˜åˆ†ææ•°æ®ï¼ˆæ¥è‡ª build_analysis.py çš„ problems actionï¼‰
        
    Returns:
        Markdownæ ¼å¼çš„é—®é¢˜å¯¼å‘æŠ¥å‘Š
    """
    today = datetime.now().strftime("%Y-%m-%d")
    days = data.get("analysis_period_days", 7)
    severity = data.get("severity", "low")
    
    severity_map = {
        "high": "ğŸ”´ ä¸¥é‡",
        "medium": "ğŸŸ¡ ä¸­ç­‰",
        "low": "ğŸŸ¢ è‰¯å¥½"
    }
    
    report = f"""# é—¨ç¦æ„å»ºé—®é¢˜åˆ†ææŠ¥å‘Š - {today}

> åˆ†æå‘¨æœŸ: æœ€è¿‘ **{days}** å¤© | é—®é¢˜ç­‰çº§: {severity_map.get(severity, 'æœªçŸ¥')}

"""
    
    # æ ¸å¿ƒé—®é¢˜æ¦‚è§ˆ
    summary = data.get("summary", {})
    report += f"""## ğŸ“‹ é—®é¢˜æ¦‚è§ˆ

| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|-----|------|------|
| å‘ç°é—®é¢˜æ•° | **{summary.get('total_problems', 0)}** | éœ€è¦å…³æ³¨çš„é—®é¢˜æ€»æ•° |
| è½åå¹³å° | **{summary.get('lagging_platforms', 0)}** ä¸ª | P95é«˜äºæ•´ä½“æ°´å¹³ |
| æ¶åŒ–å¹³å° | **{summary.get('worsening_platforms', 0)}** ä¸ª | è€—æ—¶è¶‹åŠ¿åœ¨å¢åŠ  |
| æ”¹å–„å¹³å° | **{summary.get('improving_platforms', 0)}** ä¸ª | è€—æ—¶è¶‹åŠ¿åœ¨å‡å°‘ |
| æ•´ä½“P95 | **{summary.get('overall_p95_minutes', 0)}** åˆ†é’Ÿ | å…¨å±€åŸºå‡†çº¿ |

"""
    
    # é—®é¢˜åˆ—è¡¨
    problems = data.get("problems", [])
    if problems:
        report += "## ğŸš¨ å‘ç°çš„é—®é¢˜\n\n"
        for i, problem in enumerate(problems, 1):
            report += f"{i}. {problem}\n"
        report += "\n"
    else:
        report += "## âœ… çŠ¶æ€è‰¯å¥½\n\nå½“å‰æœªå‘ç°æ˜¾è‘—é—®é¢˜ï¼Œç»§ç»­ä¿æŒã€‚\n\n"
    
    # è¯¦ç»†åˆ†æ - P95è½åå¹³å°
    details = data.get("details", {})
    lagging = details.get("lagging_analysis", {})
    lagging_platforms = lagging.get("lagging_platforms", [])
    
    if lagging_platforms:
        report += f"""## ğŸ¢ P95è½åçš„å¹³å°

> æ•´ä½“P95: **{lagging.get('overall_p95_minutes', 0)}** åˆ†é’Ÿï¼Œä»¥ä¸‹å¹³å°é«˜äºæ­¤åŸºå‡†

| æ’å | å¹³å° | æ„å»ºæ•° | P50 | P95 | å·®è· | å‚å•† |
|-----|------|--------|-----|-----|------|------|
"""
        for i, p in enumerate(lagging_platforms[:10], 1):
            icon = "ğŸ”´" if float(p.get("gap_percent", 0)) > 15 else "ğŸŸ¡"
            report += f"| {i} {icon} | {p.get('display_name', p.get('platform', ''))} | {p.get('build_count', 0)} | {p.get('p50_minutes', 0)} | {p.get('p95_minutes', 0)} | +{p.get('gap_percent', 0)}% | {p.get('vendor', '')} |\n"
        report += "\n"
        
        # å‚å•†åˆ†æ
        vendor_stats = {}
        for p in lagging_platforms:
            v = p.get("vendor", "å…¶ä»–")
            if v not in vendor_stats:
                vendor_stats[v] = 0
            vendor_stats[v] += 1
        
        if vendor_stats:
            report += "**æŒ‰å‚å•†ç»Ÿè®¡è½åå¹³å°æ•°:**\n"
            for v, count in sorted(vendor_stats.items(), key=lambda x: x[1], reverse=True):
                report += f"- {v}: {count} ä¸ª\n"
            report += "\n"
    
    # å¥åº·å¹³å°ä½œä¸ºå‚è€ƒ
    healthy = lagging.get("healthy_platforms", [])
    if healthy:
        report += "**å¥åº·å¹³å°å‚è€ƒï¼ˆå¯å­¦ä¹ ï¼‰:**\n"
        for p in healthy[:3]:
            report += f"- âœ… {p.get('display_name', p.get('platform', ''))}: P95={p.get('p95_minutes', 0)}åˆ†é’Ÿ\n"
        report += "\n"
    
    # è¶‹åŠ¿å˜åŒ–
    trends = details.get("trend_analysis", {})
    worsening = trends.get("worsening_platforms", [])
    improving = trends.get("improving_platforms", [])
    
    if worsening or improving:
        report += f"""## ğŸ“ˆ è¶‹åŠ¿å˜åŒ–

> å¯¹æ¯”å‘¨æœŸ: {trends.get('comparison_period', 'æœ€è¿‘3å¤© vs ä¹‹å‰3å¤©')}

"""
        if worsening:
            report += "### æ¶åŒ–ä¸­çš„å¹³å°\n\n"
            report += "| å¹³å° | å½“å‰å¹³å‡ | ä¹‹å‰å¹³å‡ | å˜åŒ– |\n"
            report += "|------|---------|---------|------|\n"
            for p in worsening[:5]:
                report += f"| ğŸ“ˆ {p.get('display_name', p.get('platform', ''))} | {p.get('recent_avg_minutes', 0)}åˆ†é’Ÿ | {p.get('prev_avg_minutes', 0)}åˆ†é’Ÿ | +{p.get('change_percent', 0)}% |\n"
            report += "\n"
        
        if improving:
            report += "### æ”¹å–„ä¸­çš„å¹³å°\n\n"
            report += "| å¹³å° | å½“å‰å¹³å‡ | ä¹‹å‰å¹³å‡ | å˜åŒ– |\n"
            report += "|------|---------|---------|------|\n"
            for p in improving[:5]:
                report += f"| ğŸ“‰ {p.get('display_name', p.get('platform', ''))} | {p.get('recent_avg_minutes', 0)}åˆ†é’Ÿ | {p.get('prev_avg_minutes', 0)}åˆ†é’Ÿ | {p.get('change_percent', 0)}% |\n"
            report += "\n"
    
    # ç»„ä»¶ç“¶é¢ˆåˆ†æ
    components = details.get("component_analysis", {})
    comp_list = components.get("components", [])
    
    if comp_list:
        report += """## ğŸ§© ç»„ä»¶ç“¶é¢ˆåˆ†æ

"""
        # ç»„ä»¶æ´å¯Ÿ
        insights = components.get("insights", [])
        for insight in insights:
            report += f"- {insight}\n"
        
        report += "\n**P95æœ€æ…¢çš„ç»„ä»¶:**\n\n"
        report += "| ç»„ä»¶ | æ„å»ºæ•° | P50 | P95 | å¤æ‚åº¦ |\n"
        report += "|------|--------|-----|-----|--------|\n"
        for c in comp_list[:7]:
            complexity = "é«˜" if c.get("is_complex") else "ä½"
            report += f"| {c.get('component', '')} | {c.get('build_count', 0)} | {c.get('p50_minutes', 0)}åˆ†é’Ÿ | {c.get('p95_minutes', 0)}åˆ†é’Ÿ | {complexity} |\n"
        report += "\n"
    
    # äººå‘˜åˆ†æï¼ˆç®€ç•¥ï¼‰
    users = details.get("user_analysis", {})
    if users.get("total_users", 0) > 0:
        report += f"""## ğŸ‘¤ äººå‘˜ç»´åº¦åˆ†æ

- åˆ†æç”¨æˆ·æ•°: **{users.get('total_users', 0)}** äºº
- å¹³å‡æ„å»ºè€—æ—¶: **{users.get('avg_build_time_minutes', 0)}** åˆ†é’Ÿ
- éœ€å…³æ³¨ç”¨æˆ·æ•°: **{users.get('users_need_attention', 0)}** äººï¼ˆå¹³å‡è€—æ—¶é«˜äºæ•´ä½“30%ï¼‰

"""
        user_insights = users.get("insights", [])
        for insight in user_insights:
            report += f"- {insight}\n"
        report += "\n"
    
    # å»ºè®®
    suggestions = data.get("suggestions", [])
    if suggestions:
        report += "## ğŸ’¡ æ”¹è¿›å»ºè®®\n\n"
        for i, s in enumerate(suggestions[:8], 1):
            report += f"{i}. {s}\n"
        report += "\n"
    
    report += f"""---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*æ•°æ®æ¥æº: é—¨ç¦æ„å»ºæ•°æ®åº“ (rn_test.personal_build)*
*æŠ¥å‘Šç±»å‹: é—®é¢˜å¯¼å‘åˆ†æ*
"""
    
    return report


def main():
    """
    ä¸»å‡½æ•°ï¼šä»stdinè¯»å–åˆ†æç»“æœï¼Œç”ŸæˆæŠ¥å‘Š
    
    è¾“å…¥JSONæ ¼å¼ï¼š
    {
        "report_type": "gerrit" | "build" | "build_problems" | "combined",
        "gerrit_data": {...},  # å¯é€‰ï¼Œç”¨äºgerritæˆ–combinedæŠ¥å‘Š
        "build_data": {...},   # å¯é€‰ï¼Œç”¨äºbuildæˆ–combinedæŠ¥å‘Š
        "metrics": {...},      # å‘åå…¼å®¹ï¼šgerritæŠ¥å‘Šçš„metrics
        "anomalies": [...]     # å‘åå…¼å®¹ï¼šgerritæŠ¥å‘Šçš„anomalies
    }
    """
    try:
        # ä»stdinè¯»å–JSONæ•°æ®
        input_data = sys.stdin.read()
        data = json.loads(input_data)
        
        report_type = data.get("report_type", "gerrit")
        
        if report_type == "build":
            # æ„å»ºåˆ†ææŠ¥å‘Šï¼ˆåŸºç¡€æŒ‡æ ‡ï¼‰
            build_data = data.get("build_data", data)
            report = generate_build_report(build_data)
        elif report_type == "build_problems" or report_type == "problem_analysis":
            # é—®é¢˜å¯¼å‘çš„æ„å»ºåˆ†ææŠ¥å‘Šï¼ˆæ¨èï¼‰
            build_data = data.get("build_data", data)
            report = generate_problem_report(build_data)
        elif report_type == "combined":
            # ç»¼åˆæŠ¥å‘Š
            report = generate_combined_report(
                gerrit_data=data.get("gerrit_data"),
                build_data=data.get("build_data")
            )
        else:
            # é»˜è®¤ï¼šGerritä»£ç å®¡æŸ¥æŠ¥å‘Šï¼ˆå‘åå…¼å®¹ï¼‰
            report = generate_efficiency_report(
                metrics=data.get('metrics', {}),
                anomalies=data.get('anomalies', [])
            )

        # è¾“å‡ºæŠ¥å‘Š
        print(report)

        return 0
    except Exception as e:
        print(f"Error generating report: {e}", file=sys.stderr)
        return 1


if __name__ == "__main__":
    sys.exit(main())
