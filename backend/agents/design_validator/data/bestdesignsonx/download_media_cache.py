#!/usr/bin/env python3
"""
é¢„ä¸‹è½½æ‰€æœ‰å›¾ç‰‡åˆ° media_cache ç›®å½•ã€‚

åœ¨æœ¬åœ°ï¼ˆèƒ½è®¿é—®å¤–ç½‘çš„æœºå™¨ï¼‰è¿è¡Œæ­¤è„šæœ¬ï¼Œ
å°†å›¾ç‰‡ç¼“å­˜ä¸‹è½½å¥½åéƒ¨ç½²åˆ°æœåŠ¡å™¨ï¼Œ
ä»£ç†æ¥å£æ£€æµ‹åˆ°ç¼“å­˜æ–‡ä»¶å­˜åœ¨ä¼šç›´æ¥è¿”å›ï¼Œä¸å†è¯·æ±‚å¤–ç½‘ã€‚

ç”¨æ³•:
    python3 download_media_cache.py
"""
import json
import hashlib
import io
import sys
from pathlib import Path
from urllib.parse import urlparse

import httpx

# å°è¯•å¯¼å…¥ Pillow ç”¨äº AVIF â†’ JPEG è½¬æ¢
try:
    from PIL import Image
    try:
        import pillow_heif
        pillow_heif.register_heif_opener()
        pillow_heif.register_avif_opener()
    except ImportError:
        pass
    PILLOW_AVAILABLE = True
except ImportError:
    PILLOW_AVAILABLE = False
    print("âš ï¸  Pillow æœªå®‰è£…ï¼ŒAVIF å›¾ç‰‡ä¸ä¼šè¢«è½¬æ¢ä¸º JPEG")

DATA_FILE = Path(__file__).parent / "index.json"
CACHE_DIR = Path(__file__).parent / "media_cache"
CACHE_DIR.mkdir(parents=True, exist_ok=True)


def collect_urls(data: dict) -> set:
    """ä» index.json ä¸­æå–æ‰€æœ‰åª’ä½“å’Œå¤´åƒ URL"""
    urls = set()
    for post in data.get("posts", {}).values():
        for url in post.get("media_urls", []):
            if url:
                urls.add(url)
        for item in post.get("video_urls", []):
            if isinstance(item, str) and item:
                urls.add(item)
            elif isinstance(item, dict):
                src = item.get("src", "")
                if src:
                    urls.add(src)
        avatar = post.get("avatar_url", "")
        if avatar:
            urls.add(avatar)
    return urls


def cache_path_for(url: str) -> Path:
    """ä¸ design_feed.py ä¸­çš„ç¼“å­˜é€»è¾‘å®Œå…¨ä¸€è‡´"""
    url_hash = hashlib.md5(url.encode()).hexdigest()
    parsed = urlparse(url)
    ext = Path(parsed.path).suffix or ".jpg"

    needs_conversion = ext.lower() in [".avif", ".webp"] and PILLOW_AVAILABLE
    cache_ext = ".jpg" if needs_conversion else ext
    return CACHE_DIR / f"{url_hash}{cache_ext}", needs_conversion


def download_and_cache(url: str, client: httpx.Client) -> bool:
    """ä¸‹è½½å•ä¸ª URL å¹¶ç¼“å­˜"""
    cache_file, needs_conversion = cache_path_for(url)

    if cache_file.exists():
        return True  # å·²ç¼“å­˜

    try:
        resp = client.get(url)
        resp.raise_for_status()
        image_bytes = resp.content

        if needs_conversion:
            try:
                img = Image.open(io.BytesIO(image_bytes))
                if img.mode in ("RGBA", "LA", "P"):
                    img = img.convert("RGB")
                output = io.BytesIO()
                img.save(output, format="JPEG", quality=90)
                image_bytes = output.getvalue()
            except Exception as e:
                print(f"  âš ï¸  è½¬æ¢å¤±è´¥ ({e})ï¼Œä¿å­˜åŸå§‹æ ¼å¼")
                # ä¿å­˜åŸå§‹æ ¼å¼
                parsed = urlparse(url)
                ext = Path(parsed.path).suffix or ".jpg"
                cache_file = CACHE_DIR / f"{hashlib.md5(url.encode()).hexdigest()}{ext}"

        cache_file.write_bytes(image_bytes)
        return True

    except httpx.HTTPStatusError as e:
        print(f"  âŒ HTTP {e.response.status_code}")
        return False
    except Exception as e:
        print(f"  âŒ {e}")
        return False


def main():
    if not DATA_FILE.exists():
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {DATA_FILE}")
        sys.exit(1)

    with open(DATA_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)

    urls = collect_urls(data)
    print(f"ğŸ“Š å…±å‘ç° {len(urls)} ä¸ªåª’ä½“ URL")

    success = 0
    failed = 0

    with httpx.Client(
        timeout=httpx.Timeout(connect=10.0, read=30.0, write=10.0, pool=10.0),
        follow_redirects=True,
    ) as client:
        for i, url in enumerate(sorted(urls), 1):
            short = url.split("/")[-1][:40]
            print(f"[{i}/{len(urls)}] {short}...", end=" ", flush=True)

            if download_and_cache(url, client):
                success += 1
                print("âœ…")
            else:
                failed += 1

    print(f"\nğŸ“¦ å®Œæˆ! æˆåŠŸ: {success}, å¤±è´¥: {failed}")
    print(f"ğŸ“ ç¼“å­˜ç›®å½•: {CACHE_DIR}")
    print(f"ğŸ’¡ å°† media_cache/ éƒ¨ç½²åˆ°æœåŠ¡å™¨åŒè·¯å¾„å³å¯")


if __name__ == "__main__":
    main()
